{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quickstart\n",
        "\n",
        "This notebook shows how to get started with using x.infer.\n",
        "\n",
        "x.infer relies on PyTorch and torchvision, so make sure you have it installed on your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -Uqq torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check if PyTorch is installed by checking the version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_DEOCy61Mlg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also let's check if CUDA is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MCW7-AN16Rq",
        "outputId": "9520b079-79a0-45f1-c7a8-7f0deb3cfe68"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "x.infer relies on various optional dependencies like transformers, ultralytics, timm, etc.\n",
        "You don't need to install these dependencies if you don't want to. Just install x.infer with the dependencies you want.\n",
        "\n",
        "For example, if you'd like to use models from the transformers library, you can install the `transformers` extra:\n",
        "\n",
        "\n",
        "```bash\n",
        "pip install -Uqq \"xinfer[transformers]\"\n",
        "```\n",
        "\n",
        "To install all the dependencies, you can run:\n",
        "```bash\n",
        "pip install -Uqq \"xinfer[all]\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_07_qHW18yu"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq \"xinfer[transformers]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's recommended to restart the kernel once all the dependencies are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython import get_ipython\n",
        "get_ipython().kernel.do_shutdown(restart=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once completed, let's import x.infer, check the version and list all the models available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dnth/mambaforge-pypy3/envs/xinfer-test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0.5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                            Available Models                             </span>\n",
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Implementation </span>â”ƒ<span style=\"font-weight: bold\"> Model ID                       </span>â”ƒ<span style=\"font-weight: bold\"> Input --&gt; Output    </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b-coco </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-flan-t5-xxl   </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b      </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-2.7b      </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> vikhyatk/moondream2            </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                            Available Models                             \u001b[0m\n",
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mImplementation\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mModel ID                      \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mInput --> Output   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b-coco\u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-flan-t5-xxl  \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b     \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-2.7b     \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mvikhyatk/moondream2           \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import xinfer\n",
        "\n",
        "print(xinfer.__version__)\n",
        "xinfer.list_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because we only installed the `transformers` extra, we can only use models from the `transformers` library.\n",
        "\n",
        "You can pick any model from the list of models available.\n",
        "Let's create a model from the `vikhyatk/moondream2` model. We can optionally specify the device and dtype. By default, the model is created on the CPU and the dtype is `float32`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "l2bwrpAn2FR-",
        "outputId": "45e50aef-f1c5-4eec-f7c3-63c75860fc4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-10-17 01:47:53.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.moondream\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mModel: vikhyatk/moondream2\u001b[0m\n",
            "\u001b[32m2024-10-17 01:47:53.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.moondream\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mRevision: 2024-08-26\u001b[0m\n",
            "\u001b[32m2024-10-17 01:47:53.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.moondream\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mDevice: cuda\u001b[0m\n",
            "\u001b[32m2024-10-17 01:47:53.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.moondream\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mDtype: float16\u001b[0m\n",
            "PhiForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
          ]
        }
      ],
      "source": [
        "model = xinfer.create_model(\"vikhyatk/moondream2\", device=\"cuda\", dtype=\"float16\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have the model, let's infer an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "image_url = \"https://raw.githubusercontent.com/vikhyat/moondream/main/assets/demo-1.jpg\"\n",
        "Image.open(requests.get(image_url, stream=True).raw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can pass in a url or the path to an image file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'An anime-style illustration depicts a young girl with white hair and green eyes, wearing a white jacket and holding a large burger, seated at a table with a plate of food in front of her.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = \"https://raw.githubusercontent.com/vikhyat/moondream/main/assets/demo-1.jpg\"\n",
        "prompt = \"Caption this image.\"\n",
        "\n",
        "model.infer(image, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you'd like to generate a longer caption, you can do so by setting the `max_new_tokens` parameter. You can also pass in any generation parameters supported by the `transformers` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The image depicts a young girl with long, white hair and blue eyes sitting at a table, holding a large burger in her hands. The background shows a dimly lit room with a window, suggesting an indoor setting.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = \"https://raw.githubusercontent.com/vikhyat/moondream/main/assets/demo-1.jpg\"\n",
        "prompt = \"Caption this image highlighting the focus of the image and the background in detail.\"\n",
        "\n",
        "model.infer(image, prompt, max_new_tokens=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you'd like to see the inference stats, you can do so by calling the `print_stats` method. This might be useful if you're running some sort of benchmark on the inference time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "F0x1uwK42IbP",
        "outputId": "54903d6b-f81e-4f28-da4d-a4398bd6e532"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                    Model Stats                    </span>\n",
              "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
              "â”‚<span style=\"font-weight: bold\"> Attribute                 </span>â”‚<span style=\"font-weight: bold\"> Value               </span>â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model ID                  </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> vikhyatk/moondream2 </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Device                    </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> cuda                </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Dtype                     </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> torch.float16       </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Number of Inferences      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> 15                  </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Total Inference Time (ms) </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> 9590.0959           </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Average Latency (ms)      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> 639.3397            </span>â”‚\n",
              "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                    Model Stats                    \u001b[0m\n",
              "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
              "â”‚\u001b[1m \u001b[0m\u001b[1mAttribute                \u001b[0m\u001b[1m \u001b[0mâ”‚\u001b[1m \u001b[0m\u001b[1mValue              \u001b[0m\u001b[1m \u001b[0mâ”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mModel ID                 \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mvikhyatk/moondream2\u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mDevice                   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mcuda               \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mDtype                    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mtorch.float16      \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mNumber of Inferences     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m15                 \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mTotal Inference Time (ms)\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m9590.0959          \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36mAverage Latency (ms)     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m639.3397           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.stats.print_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiRCgGBB3ACu"
      },
      "source": [
        "Finally, you can also run batch inference. You'll have to pass in a list of images and prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The image depicts a young girl with long, white hair and blue eyes sitting at a table, holding a large burger in her hands. The background shows a cozy indoor setting with a window and a chair visible.',\n",
              " 'The image depicts a young girl with long, white hair and blue eyes sitting at a table, holding a large burger in her hands. The background shows a cozy indoor setting with a window and a chair visible.']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model.infer_batch([image, image], [prompt, prompt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's it! You've successfully run inference with x.infer. \n",
        "\n",
        "Hope this simplifies the process of running inference with your favorite computer vision models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "    <img src=\"https://raw.githubusercontent.com/dnth/x.infer/refs/heads/main/assets/github_banner.png\" alt=\"x.infer\" width=\"600\"/>\n",
        "    <br />\n",
        "    <br />\n",
        "    <a href=\"https://dnth.github.io/x.infer\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Explore the docs Â»</strong></a>\n",
        "    <br />\n",
        "    <a href=\"#quickstart\" target=\"_blank\" rel=\"noopener noreferrer\">Quickstart</a>\n",
        "    Â·\n",
        "    <a href=\"https://github.com/dnth/x.infer/issues/new?assignees=&labels=Feature+Request&projects=&template=feature_request.md\" target=\"_blank\" rel=\"noopener noreferrer\">Feature Request</a>\n",
        "    Â·\n",
        "    <a href=\"https://github.com/dnth/x.infer/issues/new?assignees=&labels=bug&projects=&template=bug_report.md\" target=\"_blank\" rel=\"noopener noreferrer\">Report Bug</a>\n",
        "    Â·\n",
        "    <a href=\"https://github.com/dnth/x.infer/discussions\" target=\"_blank\" rel=\"noopener noreferrer\">Discussions</a>\n",
        "    Â·\n",
        "    <a href=\"https://dicksonneoh.com/\" target=\"_blank\" rel=\"noopener noreferrer\">About</a>\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
