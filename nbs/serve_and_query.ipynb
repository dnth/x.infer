{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:30:25,176\tINFO worker.py:1807 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO 2024-11-11 12:30:26,979 serve 39171 api.py:277 - Started Serve in namespace \"serve\".\n",
      "INFO 2024-11-11 12:30:26,991 serve 39171 api.py:259 - Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "WARNING 2024-11-11 12:30:26,992 serve 39171 api.py:85 - The new client HTTP config differs from the existing one in the following fields: ['location']. The new HTTP config is ignored.\n",
      "\u001b[36m(ServeController pid=39453)\u001b[0m INFO 2024-11-11 12:30:27,044 controller 39453 deployment_state.py:1604 - Deploying new version of Deployment(name='XInferModel', app='default') (initial target replicas: 1).\n",
      "\u001b[36m(ProxyActor pid=39459)\u001b[0m INFO 2024-11-11 12:30:26,964 proxy 192.168.100.201 proxy.py:1191 - Proxy starting on node 159f2e944d96ea4dcd2d8b019e272129d2225de6d20b721360921424 (HTTP port: 8000).\n",
      "\u001b[36m(ServeController pid=39453)\u001b[0m INFO 2024-11-11 12:30:27,148 controller 39453 deployment_state.py:1850 - Adding 1 replica to Deployment(name='XInferModel', app='default').\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=39461)\u001b[0m 2024-11-11 12:30:31.248 | INFO     | xinfer.models:__init__:63 - Model: vikhyatk/moondream2\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=39461)\u001b[0m 2024-11-11 12:30:31.248 | INFO     | xinfer.models:__init__:64 - Device: cuda\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=39461)\u001b[0m 2024-11-11 12:30:31.248 | INFO     | xinfer.models:__init__:65 - Dtype: float16\n",
      "INFO 2024-11-11 12:30:39,092 serve 39171 client.py:492 - Deployment 'XInferModel:vgjpzw6s' is ready at `http://127.0.0.1:8000/`. component=serve deployment=XInferModel\n",
      "INFO 2024-11-11 12:30:39,094 serve 39171 api.py:549 - Deployed app 'default' successfully.\n",
      "\u001b[32m2024-11-11 12:30:39.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.serve\u001b[0m:\u001b[36mserve_model\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mOpen FastAPI docs at http://127.0.0.1:8000/docs\u001b[0m\n",
      "\u001b[32m2024-11-11 12:30:39.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.serve\u001b[0m:\u001b[36mserve_model\u001b[0m:\u001b[36m175\u001b[0m - \u001b[1mRunning server in non-blocking mode, remember to call serve.shutdown() to stop the server\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeploymentHandle(deployment='XInferModel')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ServeReplica:default:XInferModel pid=39461)\u001b[0m INFO 2024-11-11 12:30:39,542 default_XInferModel 0qe66qm6 0abf8959-ea62-4738-b848-53a13c1de2a4 /v1/chat/completions replica.py:378 - __CALL__ OK 415.9ms\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=39461)\u001b[0m INFO 2024-11-11 12:30:49,040 default_XInferModel 0qe66qm6 8a73d848-d884-4995-aa75-7c03bf553bb7 /v1/chat/completions replica.py:378 - __CALL__ OK 3.2ms\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=39461)\u001b[0m INFO 2024-11-11 12:31:40,437 default_XInferModel 0qe66qm6 47d45c00-22be-463d-9a75-fb4b7b6c713d /v1/chat/completions replica.py:378 - __CALL__ OK 314.8ms\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=39461)\u001b[0m INFO 2024-11-11 12:32:12,370 default_XInferModel 0qe66qm6 b6d87e93-26d8-4281-9aab-640015be2a73 /v1/chat/completions replica.py:378 - __CALL__ OK 280.0ms\n"
     ]
    }
   ],
   "source": [
    "import xinfer\n",
    "xinfer.serve_model(\n",
    "    \"vikhyatk/moondream2\",\n",
    "    device=\"cuda\",\n",
    "    dtype=\"float16\",\n",
    "    blocking=False,\n",
    "    open_api_docs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': None, 'boxes': None, 'masks': None, 'poses': None, 'text': 'A parade with a marching'}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"dummy\",\n",
    "    base_url=\"http://127.0.0.1:8000/v1\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"vikhyatk/moondream2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"https://raw.githubusercontent.com/dnth/x.infer/main/assets/demo/00aa2580828a9009.jpg\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"infer_kwargs\",\n",
    "                    \"infer_kwargs\": {\"text\": \"Caption.\", \"max_new_tokens\": 5}\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   841  100   363  100   478   1139   1500 --:--:-- --:--:-- --:--:--  2644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-1731299500436353478\",\"object\":\"chat.completion\",\"created\":1731299500,\"model\":\"vikhyatk/moondream2\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":{\"categories\":null,\"boxes\":null,\"masks\":null,\"poses\":null,\"text\":\"A parade with a marching\"}},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":0,\"total_tokens\":0}}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl http://127.0.0.1:8000/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer dummy\" \\\n",
    "  -d '{\n",
    "    \"model\": \"vikhyatk/moondream2\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": \"https://raw.githubusercontent.com/dnth/x.infer/main/assets/demo/00aa2580828a9009.jpg\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"infer_kwargs\",\n",
    "            \"infer_kwargs\": {\n",
    "              \"text\": \"Caption.\",\n",
    "              \"max_new_tokens\": 5\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xinfer\n",
    "xinfer.serve_model(\n",
    "    \"ultralytics/yolov8n\",\n",
    "    device=\"cuda\",\n",
    "    dtype=\"float16\",\n",
    "    blocking=False,\n",
    "    open_api_docs=False,\n",
    "    port=8001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"dummy\",\n",
    "    base_url=\"http://127.0.0.1:8001/v1\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"ultralytics/yolov8n\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"https://raw.githubusercontent.com/dnth/x.infer/main/assets/demo/00aa2580828a9009.jpg\"\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "\n",
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xinfer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
