{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 01:37:19,706\tINFO worker.py:1807 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO 2024-11-10 01:37:21,606 serve 76941 api.py:277 - Started Serve in namespace \"serve\".\n",
      "\u001b[36m(ProxyActor pid=77224)\u001b[0m INFO 2024-11-10 01:37:21,591 proxy 192.168.100.60 proxy.py:1191 - Proxy starting on node 4205d25ed683c11fef9a3a6b3cfefe334d62e5689afa3d6aa86c745f (HTTP port: 8000).\n",
      "INFO 2024-11-10 01:37:21,620 serve 76941 api.py:259 - Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "WARNING 2024-11-10 01:37:21,621 serve 76941 api.py:85 - The new client HTTP config differs from the existing one in the following fields: ['location']. The new HTTP config is ignored.\n",
      "\u001b[36m(ServeController pid=77225)\u001b[0m INFO 2024-11-10 01:37:21,748 controller 77225 deployment_state.py:1604 - Deploying new version of Deployment(name='XInferModel', app='default') (initial target replicas: 1).\n",
      "\u001b[36m(ServeController pid=77225)\u001b[0m INFO 2024-11-10 01:37:21,851 controller 77225 deployment_state.py:1850 - Adding 1 replica to Deployment(name='XInferModel', app='default').\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=77231)\u001b[0m 2024-11-10 01:37:26.190 | INFO     | xinfer.models:__init__:63 - Model: ultralytics/yolov8n\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=77231)\u001b[0m 2024-11-10 01:37:26.190 | INFO     | xinfer.models:__init__:64 - Device: cuda\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=77231)\u001b[0m 2024-11-10 01:37:26.190 | INFO     | xinfer.models:__init__:65 - Dtype: float16\n",
      "INFO 2024-11-10 01:37:26,678 serve 76941 client.py:492 - Deployment 'XInferModel:etjv2ya6' is ready at `http://127.0.0.1:8000/`. component=serve deployment=XInferModel\n",
      "INFO 2024-11-10 01:37:26,679 serve 76941 api.py:549 - Deployed app 'default' successfully.\n",
      "\u001b[32m2024-11-10 01:37:26.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.serve\u001b[0m:\u001b[36mserve_model\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mOpen FastAPI docs at http://127.0.0.1:8000/docs\u001b[0m\n",
      "\u001b[32m2024-11-10 01:37:26.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.serve\u001b[0m:\u001b[36mserve_model\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mRunning server in non-blocking mode, remember to call serve.shutdown() to stop the server\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeploymentHandle(deployment='XInferModel')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xinfer\n",
    "xinfer.serve_model(\n",
    "    # \"vikhyatk/moondream2\",\n",
    "    \"ultralytics/yolov8n\",\n",
    "    device=\"cuda\",\n",
    "    dtype=\"float16\",\n",
    "    blocking=False,\n",
    "    open_api_docs=True,\n",
    "    # port=8001,\n",
    "    # deployment_kwargs={\n",
    "    #     \"num_replicas\": 1,\n",
    "    #     \"ray_actor_options\": {\"num_gpus\": 0.5}\n",
    "    # },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "\n",
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X 'POST' \\\n",
    "  'http://127.0.0.1:8000/infer' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "  \"image\": \"https://raw.githubusercontent.com/dnth/x.infer/refs/heads/main/assets/demo/00aa2580828a9009.jpg\",\n",
    "  \"infer_kwargs\": {\"prompt\": \"Caption this image\"}\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -X 'POST' \\\n",
    "  'http://127.0.0.1:8000/v1/chat/completions' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "  \"model\": \"vikhyatk/moondream2\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Caption this image\"\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ServeReplica:default:XInferModel pid=77231)\u001b[0m \n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=77231)\u001b[0m 0: 480x640 15 persons, 1 truck, 71.4ms\n",
      "\u001b[36m(ServeReplica:default:XInferModel pid=77231)\u001b[0m Speed: 2.6ms preprocess, 71.4ms inference, 71.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': None, 'boxes': [{'x1': 169.3000030517578, 'y1': 372.8000183105469, 'x2': 260.3999938964844, 'y2': 616.0, 'score': 0.82666015625, 'label': 'person'}, {'x1': 720.7999877929688, 'y1': 5.599999904632568, 'x2': 1023.2000122070312, 'y2': 727.2000122070312, 'score': 0.8154296875, 'label': 'person'}, {'x1': 531.6000366210938, 'y1': 354.8000183105469, 'x2': 710.0, 'y2': 726.7999877929688, 'score': 0.74853515625, 'label': 'person'}, {'x1': 0.02500000037252903, 'y1': 414.8000183105469, 'x2': 43.60000228881836, 'y2': 543.6000366210938, 'score': 0.732421875, 'label': 'person'}, {'x1': 434.3999938964844, 'y1': 334.0, 'x2': 477.6000061035156, 'y2': 429.6000061035156, 'score': 0.6494140625, 'label': 'person'}, {'x1': 56.900001525878906, 'y1': 167.10000610351562, 'x2': 388.8000183105469, 'y2': 532.0, 'score': 0.640625, 'label': 'truck'}, {'x1': 385.6000061035156, 'y1': 346.3999938964844, 'x2': 420.3999938964844, 'y2': 428.8000183105469, 'score': 0.5859375, 'label': 'person'}, {'x1': 718.4000244140625, 'y1': 177.5, 'x2': 812.0, 'y2': 378.3999938964844, 'score': 0.56689453125, 'label': 'person'}, {'x1': 488.3999938964844, 'y1': 365.20001220703125, 'x2': 547.6000366210938, 'y2': 539.6000366210938, 'score': 0.490234375, 'label': 'person'}, {'x1': 555.2000122070312, 'y1': 330.0, 'x2': 832.0, 'y2': 731.6000366210938, 'score': 0.4814453125, 'label': 'person'}, {'x1': 31.200000762939453, 'y1': 419.20001220703125, 'x2': 74.20000457763672, 'y2': 529.6000366210938, 'score': 0.375732421875, 'label': 'person'}, {'x1': 40.775001525878906, 'y1': 426.3999938964844, 'x2': 74.0, 'y2': 526.4000244140625, 'score': 0.3583984375, 'label': 'person'}, {'x1': 484.8000183105469, 'y1': 357.20001220703125, 'x2': 516.7999877929688, 'y2': 427.6000061035156, 'score': 0.34765625, 'label': 'person'}, {'x1': 549.6000366210938, 'y1': 196.8000030517578, 'x2': 815.2000122070312, 'y2': 730.4000244140625, 'score': 0.26904296875, 'label': 'person'}, {'x1': 25.100000381469727, 'y1': 417.6000061035156, 'x2': 64.20000457763672, 'y2': 530.4000244140625, 'score': 0.26806640625, 'label': 'person'}, {'x1': 797.6000366210938, 'y1': 123.80000305175781, 'x2': 912.7999877929688, 'y2': 250.1999969482422, 'score': 0.265869140625, 'label': 'person'}], 'masks': None, 'poses': None, 'text': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ServeReplica:default:XInferModel pid=77231)\u001b[0m INFO 2024-11-10 01:37:48,267 default_XInferModel cty24bv7 4a7cd3c2-5794-4f96-b499-97b31e6cc4d6 /v1/chat/completions replica.py:378 - __CALL__ OK 814.6ms\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"dummy\",\n",
    "    base_url=\"http://127.0.0.1:8000/v1\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    # model=\"vikhyatk/moondream2\",\n",
    "    model=\"ultralytics/yolov8n\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"https://raw.githubusercontent.com/dnth/x.infer/refs/heads/main/assets/demo/00aa2580828a9009.jpg\"\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xinfer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
