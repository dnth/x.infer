{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnth/mambaforge-pypy3/envs/xinfer-test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                     Available Models                                     </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Implementation </span>â”ƒ<span style=\"font-weight: bold\"> Model ID                                        </span>â”ƒ<span style=\"font-weight: bold\"> Input --&gt; Output    </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_m38m_ft_in22k_in1k  </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_m38m_ft_in1k        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_in22k_ft_in22k_in1k </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_in22k_ft_in1k       </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_base_patch14_448.mim_in22k_ft_in22k_in1k  </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_base_patch14_448.mim_in22k_ft_in1k        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_small_patch14_336.mim_in22k_ft_in1k       </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_tiny_patch14_336.mim_in22k_ft_in1k        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b-coco                  </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-flan-t5-xxl                    </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b                       </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-2.7b                       </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> vikhyatk/moondream2                             </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                     Available Models                                     \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mImplementation\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mModel ID                                       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mInput --> Output   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_m38m_ft_in22k_in1k \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_m38m_ft_in1k       \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_in22k_ft_in22k_in1k\u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_in22k_ft_in1k      \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35meva02_base_patch14_448.mim_in22k_ft_in22k_in1k \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35meva02_base_patch14_448.mim_in22k_ft_in1k       \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35meva02_small_patch14_336.mim_in22k_ft_in1k      \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35meva02_tiny_patch14_336.mim_in22k_ft_in1k       \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b-coco                 \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-flan-t5-xxl                   \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b                      \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-2.7b                      \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mvikhyatk/moondream2                            \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xinfer\n",
    "\n",
    "# xinfer.list_models(\"vlrm-blip2-opt-2.7b\")\n",
    "xinfer.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-15 10:52:19.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.moondream\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mModel: vikhyatk/moondream2\u001b[0m\n",
      "\u001b[32m2024-10-15 10:52:19.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.moondream\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mRevision: 2024-08-26\u001b[0m\n",
      "\u001b[32m2024-10-15 10:52:19.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.moondream\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mDevice: auto\u001b[0m\n",
      "\u001b[32m2024-10-15 10:52:19.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.moondream\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mDtype: bfloat16\u001b[0m\n",
      "PhiForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: auto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxinfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvikhyatk/moondream2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbfloat16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model = xinfer.create_model(\"microsoft/git-base-coco\", \"transformers\", trust_remote_code=True)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model = xinfer.create_model(\"Salesforce/blip2-opt-2.7b\", device=\"auto\", dtype=\"bfloat16\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model = xinfer.create_model(\"sashakunitsyn/vlrm-blip2-opt-2.7b\", \"transformers\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# model = Vision2SeqModel(\"facebook/chameleon-7b\")\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# model = xinfer.create_model(model)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/xinfer/xinfer/core.py:44\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, (TimmModel, Vision2SeqModel, UltralyticsModel)):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/xinfer/xinfer/model_registry.py:38\u001b[0m, in \u001b[0;36mModelRegistry.get_model\u001b[0;34m(self, model_id, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/xinfer/xinfer/transformers/moondream.py:40\u001b[0m, in \u001b[0;36mMoondream.__init__\u001b[0;34m(self, model_id, revision, device, dtype)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model_id, device, dtype)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrevision \u001b[38;5;241m=\u001b[39m revision\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/xinfer/xinfer/transformers/moondream.py:72\u001b[0m, in \u001b[0;36mMoondream.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\n\u001b[0;32m---> 72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax-autotune\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/xinfer-test/lib/python3.11/site-packages/transformers/modeling_utils.py:2958\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2954\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2955\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2956\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2957\u001b[0m         )\n\u001b[0;32m-> 2958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/xinfer-test/lib/python3.11/site-packages/torch/nn/modules/module.py:1133\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move and/or cast the parameters and buffers.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \n\u001b[1;32m   1050\u001b[0m \u001b[38;5;124;03m    This can be called as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m     device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dtype\u001b[38;5;241m.\u001b[39mis_floating_point \u001b[38;5;129;01mor\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mis_complex):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: auto"
     ]
    }
   ],
   "source": [
    "model = xinfer.create_model(\"vikhyatk/moondream2\", device=\"auto\", dtype=\"bfloat16\")\n",
    "# model = xinfer.create_model(\"microsoft/git-base-coco\", \"transformers\", trust_remote_code=True)\n",
    "# model = xinfer.create_model(\"Salesforce/blip2-opt-2.7b\", device=\"auto\", dtype=\"bfloat16\")\n",
    "# model = xinfer.create_model(\"sashakunitsyn/vlrm-blip2-opt-2.7b\", \"transformers\")\n",
    "# model = xinfer.create_model(\"microsoft/kosmos-2-patch14-224\", \"transformers\")\n",
    "\n",
    "\n",
    "# model = xinfer.create_model(\n",
    "#     \"llava-hf/llava-onevision-qwen2-0.5b-ov-hf\",\n",
    "#     \"transformers\"\n",
    "# )\n",
    "\n",
    "# from xinfer.transformers import Vision2SeqModel\n",
    "\n",
    "# model = Vision2SeqModel(\"facebook/chameleon-7b\")\n",
    "# model = xinfer.create_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"https://raw.githubusercontent.com/vikhyat/moondream/main/assets/demo-1.jpg\"\n",
    "prompt = \"Describe this image. Answer:\"\n",
    "# prompt = \"<grounding> An image of\"\n",
    "\n",
    "# image = \"../assets/xinfer.jpg\"\n",
    "\n",
    "generated_text = model.infer(image, prompt, verbose=True)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "images = [image] * batch_size\n",
    "prompts = [prompt] * batch_size\n",
    "\n",
    "model.infer_batch(images, prompts, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xinfer-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
